# Machine-Learning-Final-Exam-WANGZHEN
SCMS, Wang Zhen, 25210840011
# 第五题与第七题：Iris 分类与 HMC 采样实验

本仓库包含课程作业中**第五题（分类模型对比）**与**第七题（HMC 采样混合高斯分布）**的完整代码实现与实验说明，均采用 Python 实现。

---

## 一、第七题：Iris 数据集的多模型分类

### 1. 实验目标
利用分类模型对 UCI 机器学习数据库中的 Iris 数据集进行分类，至少实现 SVM 和神经网络两种模型，并对不同模型的分类结果与计算效率进行比较。

### 2. 数据集说明
- 数据来源：UCI Machine Learning Repository  
  http://archive.ics.uci.edu/ml/datasets/Iris
- 样本数：150
- 特征数：4（花萼长度、花萼宽度、花瓣长度、花瓣宽度）
- 类别数：3（Iris-setosa、Iris-versicolor、Iris-virginica）
- 类别分布均衡：每类 50 个样本

### 3. 采用的模型
本实验共实现了 6 种典型分类模型：
- 支持向量机（SVM）
- 神经网络（多层感知机，MLP）
- Logistic 回归
- K 近邻（KNN）
- 随机森林（Random Forest）
- 朴素贝叶斯（Naive Bayes）

### 4. 实验流程
1. 从本地文件读取 Iris 数据集；
2. 对特征进行标准化处理；
3. 划分训练集与测试集（80% / 20%，分层抽样）；
4. 训练各类分类模型；
5. 计算分类准确率、混淆矩阵与分类报告；
6. 记录模型的训练时间与预测时间，用于效率对比。

### 5. 评价指标
- 分类准确率（Accuracy）
- 混淆矩阵（Confusion Matrix）
- Precision / Recall / F1-score
- 训练时间（Training Time）
- 预测时间（Prediction Time）

### 6. 实验结论（简要）
- SVM 与朴素贝叶斯在该任务中取得最高准确率；
- Iris-setosa 类别可被所有模型完全正确分类，主要误差集中在 Iris-versicolor 与 Iris-virginica 之间；
- 朴素贝叶斯在保证较高精度的同时，训练与预测速度最快；
- 随机森林在小样本、低维数据条件下优势不明显。

---

## 二、第五题：基于 HMC 的混合高斯分布采样

### 1. 题目要求
推导并实现哈密尔顿蒙特卡洛（Hamiltonian Monte Carlo, HMC）方法，对以下一维混合高斯分布进行采样：
\[
\pi(x) = 0.3 \mathcal{N}(4, 0.3) + 0.7 \mathcal{N}(7, 2)
\]
并通过定量指标描述采样分布与真实分布之间的误差。

### 2. 方法说明

#### （1）目标分布与势能函数
- 定义混合高斯分布的对数密度 \(\log \pi(x)\)
- 构造势能函数：
\[
U(x) = -\log \pi(x)
\]

#### （2）梯度计算
根据混合模型的后验责任度（responsibility），推导势能函数梯度：
\[
\nabla U(x) = r_1\frac{x-\mu_1}{\sigma_1^2} + r_2\frac{x-\mu_2}{\sigma_2^2}
\]

#### （3）HMC 采样流程
- 从动量分布 \(p \sim \mathcal{N}(0, M)\) 中采样；
- 使用 leapfrog 方法对哈密尔顿动力系统进行数值积分；
- 基于 Metropolis-Hastings 准则进行接受/拒绝；
- 为减弱周期性影响，每次迭代随机选取步数 \(L \in [L_{min}, L_{max}]\)。

#### （4）多链采样
针对双峰分布的特性，分别从两个峰值附近初始化两条马尔可夫链（x=4 与 x=7），最终合并样本以增强混合效果。

---

## 三、误差评估与诊断指标

为评价 HMC 采样结果与真实分布的接近程度，使用以下指标：

### 1. 样本矩与理论矩误差
- 均值误差：\(|\hat{\mu} - \mu|\)
- 方差误差：\(|\hat{\sigma}^2 - \sigma^2|\)

### 2. Kolmogorov–Smirnov（KS）距离
\[
D_{KS} = \sup_x |F_n(x) - F(x)|
\]
其中 \(F_n(x)\) 为经验分布函数，\(F(x)\) 为真实分布的累积分布函数。

### 3. 有效样本量（ESS）
基于样本自相关函数估计：
\[
ESS = \frac{n}{1 + 2\sum_{k=1}^K \rho_k}
\]
用于衡量样本的独立性与采样效率。

### 4. 接受率（Acceptance Rate）
统计 HMC 过程中提议状态被接受的比例，用于评估步长与轨道长度设置是否合理。

---

## 四、代码结构说明

- `final7.ipynb` / `hmc.py`（或对应脚本）
  - 第五题：Iris 分类模型实现与对比
  - 第七题：HMC 采样混合高斯分布
- `iris.data`
  - Iris 原始数据文件
- `README.md`
  - 实验说明文档（本文件）

---

## 五、运行方式

### 1. Iris 分类实验
确保 `iris.data` 与代码文件在同一目录下，运行 Notebook 或 Python 脚本即可得到各模型的分类结果与效率对比。

### 2. HMC 采样实验
直接运行脚本，将输出以下诊断信息：
- 两条链的接受率
- 合并样本数
- 有效样本量（ESS）
- 样本均值、方差与理论值的误差
- KS 距离

---

## 六、总结

- 第五题部分系统比较了多种经典分类模型在 Iris 数据集上的性能差异，验证了在小样本、低维问题中，SVM 与朴素贝叶斯具有良好的准确性与效率优势。
- 第七题部分通过 HMC 方法成功实现了对双峰混合高斯分布的高效采样，并通过矩误差、KS 距离和 ESS 等指标对采样质量进行了定量评估，验证了 HMC 在复杂分布采样问题中的有效性。
